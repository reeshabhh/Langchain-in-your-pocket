{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f4eb6a-eecb-484e-962a-d37231d6dd4c",
   "metadata": {},
   "source": [
    "# 2.2 Name Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3407b3-609f-40b7-b707-fe3ca50285a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')  # take environment variables from .env.\n",
    "\n",
    "# Code of your application, which uses environment variables (e.g. from `os.environ` or\n",
    "# `os.getenv`) as if they came from the actual environment.\n",
    "\n",
    "import os\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565e26a4-d9ec-4104-b4b3-64f1006496b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957c32ce-d41c-403b-b7a3-469380fac2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate.from_template(\" Suggest {number} names for\\\n",
    "a {domain} startup?\")\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo-instruct')\n",
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a35178-298b-49c1-aa52-eafb278ab197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Savory Solutions\n",
      "2. Kitchen Creations Co.\n",
      "3. FlavorFusion Co.\n",
      "4. Culinary Crafters\n",
      "5. The Tasteful Table Co.\n",
      "\n",
      "\n",
      "1. Synapse Intelligence\n",
      "2. Neural Nexus Solutions\n"
     ]
    }
   ],
   "source": [
    "print(chain.run({'number':'5','domain':'cooking'}))\n",
    "print(chain.run({'number':'2','domain':'AI'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d31ac-f7c4-472a-84b1-b567a38d472b",
   "metadata": {},
   "source": [
    "# 2.3 Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34bb0817-4486-42d9-91dc-3cbf0c490094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6afc686c-fb25-443e-a4d4-13b27e5eddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= PromptTemplate.from_template(\"\"\"Preprocess the given text by\n",
    "following the given steps in sequence. Follow only those steps that have\n",
    "a yes against them. Remove Number:{number},Remove punctuations:\n",
    "{punc},Word stemming:{stem} . Output just the preprocessed text. Text:\n",
    "{text}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c1b9008-0eb9-4691-a0a5-c67d8969c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo-instruct')\n",
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d5f677-3b0b-434c-b6fc-9c1d2348e912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hey I got out of in Swimming\n"
     ]
    }
   ],
   "source": [
    "print(chain.run({'text':'Hey!! I got 12 out of 20 in Swimming', 'number':\n",
    "'yes', 'punc':'yes', 'stem':'no'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "537cfd91-b8a8-4e23-a87a-0abcdfd4bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "22 13b is my flat no. rohit will be joining us forthe party\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chain.run({'text':'22 13B is my flat no. Rohit will be joining us for\\\n",
    "the party', 'number':'yes', 'punc':'no', 'stem':'yes'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb27aff-31da-4a02-995d-526542d555fb",
   "metadata": {},
   "source": [
    "# 2.4 Storyteller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "902d3c85-f4cc-49aa-879c-9820243b1ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90476d8-2771-4dab-9912-41b8f2d7c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\" Complete a {length} story\\\n",
    "using the given beginning. The genre should be {genre} and the story\\\n",
    "should have an apt ending. Beginning: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6f6bedb-909e-4193-873d-56218c9c12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY, model='gpt-3.5-turbo-instruct')\n",
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38f55fb8-1815-4652-aee3-1d9bc0c254e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " named John who loved to spend long hours working on his computer\n",
      "\n",
      "\n",
      "Once there was a coder named John who loved to spend long hours working on his computer\n",
      " He was a master at writing complex code and creating intricate programs\n",
      " His passion for coding consumed him and he often found himself losing track of time while sitting in front of his computer\n",
      "\n",
      "\n",
      "One dark and stormy night, John was working on a new project when he suddenly heard a strange noise coming from his computer\n",
      " It sounded like a faint whisper, but he couldn't make out what it was saying\n",
      " Thinking it was just his tired mind playing tricks on him, John brushed it off and continued working\n",
      "\n",
      "\n",
      "But as the night went on, the whispers grew louder and more distinct\n",
      " John started to feel uneasy and a chill ran down his spine\n",
      " He tried to ignore it, but the whispers were becoming more and more persistent\n",
      " Suddenly, his computer screen went black and a single word appeared in bold, red letters: \"HELP\n",
      "\"\n",
      "\n",
      "John's heart raced as he frantically tried to fix his computer\n",
      " But no matter what he did, the screen remained black with that haunting word in the center\n",
      " In a moment of desperation, John shouted into the darkness of his room, \"Who are you? What do you want from me?\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(chain.run({'length':'short','genre':'horror','text':'Once there\\\n",
    "was a coder'}).replace('\\n','.').split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c3b2ec7-1d2e-4766-8f72-a148aecfcc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", leaving the kingdom in chaos\n",
      "\n",
      "\n",
      "And the Queen died, leaving the kingdom in chaos\n",
      " The people were in mourning, and the royal court was in disarray\n",
      " The Queen had been loved by all, and her sudden passing had left a void in everyone's hearts\n",
      "\n",
      "\n",
      "Prince William, the Queen's only son, was devastated\n",
      " He had lost not only his mother but also his best friend\n",
      " The Queen had always been there for him, guiding him and supporting him in his duties as the future king\n",
      " And now, he was left to rule the kingdom alone\n",
      "\n",
      "\n",
      "As Prince William struggled to come to terms with his mother's death, a new challenge presented itself\n",
      " The neighboring kingdom of Montrose, ruled by the beautiful and headstrong Princess Isabella, declared war on their kingdom\n",
      " The Queen's death had left the kingdom vulnerable, and Princess Isabella saw it as an opportunity to expand her territory\n",
      "\n",
      "\n",
      "Prince William knew he had to act fast\n",
      " He gathered his advisors and generals to discuss a plan of action\n",
      " But no matter how hard they tried, they couldn't come up with a solution\n",
      " The kingdom was still in mourning, and the people were not ready for a war\n",
      "\n",
      "\n",
      "Just when all hope seemed lost, a letter arrived from Princess Isabella\n",
      " She expressed her condolences\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(chain.run({'length':'short','genre':'rom-com','text':'And\\\n",
    "the\\\n",
    "Queen died'}).replace('\\n','.').split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f7c88-82f0-414d-aaa5-055df7520431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0ece4-d88f-479a-854c-954f12bc0253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
